{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64441d2-bc5e-4800-9d01-1c4e04dc0858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69288c82-963e-46f3-8c46-34111c27cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the test set directory\n",
    "test_dir = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d2f0cf-7891-41fd-90e4-54f87982b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model architecture from the JSON file\n",
    "with open(\"model1.json\", \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12240569-2b90-4b5b-89a5-5115d62649b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from disk\n"
     ]
    }
   ],
   "source": [
    "# Load the model weights from the H5 file\n",
    "loaded_model.load_weights(\"model1.h5\")\n",
    "print(\"Model loaded from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc1acc4-1452-4e54-816a-e2aaa40cbda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the loaded model\n",
    "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4803b366-1996-4297-8743-73f7f3988bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the images and labels\n",
    "image_size = (128, 128)\n",
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b62f7d-0112-43cf-9364-e6ce81bd7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a separate file with labels or some logic to determine the label\n",
    "# For example, let's say you have a dictionary that maps file names to labels\n",
    "filename_to_label = {\n",
    "     'AppleCedarRust1.JPG': 0,\n",
    "     'AppleCedarRust2.JPG': 1,\n",
    "    # ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8e49db-72a1-4f09-b2f6-f96509784c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the files in the directory and load them\n",
    "for filename in os.listdir(test_dir):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Adjust the extensions as necessary\n",
    "        img_path = os.path.join(test_dir, filename)\n",
    "        img = load_img(img_path, target_size=image_size)\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "\n",
    "        # Get the label for the image\n",
    "        label = filename_to_label.get(filename, -1)  # Replace with your logic\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d384cdc5-b132-4c6f-83f3-fe4fce20b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e20c78-61b1-47eb-9f71-829ea0b79b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "images = images / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad37b5e-2c31-4b49-a291-159a06555a44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (0,))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a data generator\u001b[39;00m\n\u001b[0;32m      2\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator()\n\u001b[1;32m----> 3\u001b[0m test_set \u001b[38;5;241m=\u001b[39m \u001b[43mtest_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\preprocessing\\image.py:1547\u001b[0m, in \u001b[0;36mImageDataGenerator.flow\u001b[1;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[0m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow\u001b[39m(\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1490\u001b[0m     x,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1501\u001b[0m ):\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Takes data & label arrays, generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \n\u001b[0;32m   1504\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1545\u001b[0m \n\u001b[0;32m   1546\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNumpyArrayIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_class_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_class_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\preprocessing\\image.py:758\u001b[0m, in \u001b[0;36mNumpyArrayIterator.__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_misc \u001b[38;5;241m=\u001b[39m x_misc\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m--> 758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    759\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data in `NumpyArrayIterator` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have rank 4. You passed an array \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith shape\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    762\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    764\u001b[0m channels_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[channels_axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m}:\n",
      "\u001b[1;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (0,))"
     ]
    }
   ],
   "source": [
    "# Create a data generator\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_set = test_datagen.flow(images, labels, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b5f52-37a6-4ba2-8b61-608f2c6959b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the loaded model\n",
    "loss, accuracy = loaded_model.evaluate(test_set)\n",
    "print(f\"Loaded model accuracy: {accuracy*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e31678-3eaf-42d0-87f0-1b3451af0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict(test_set)\n",
    "print(\"Predictions completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
